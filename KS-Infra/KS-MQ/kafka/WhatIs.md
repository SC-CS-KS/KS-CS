# Apache Kafka - A distributed streaming platform

```md
是一款基于发布与订阅的消息系统。
它一般被称为“分布式提交日志”或者“分布式流平台”。

文件系统或者数据库提交日志用来提供所有事物的持久化记录，通过重建这些日志可以重建系统的状态。
同样地，kafka的数据是按照一定顺序持久化保存的，可以按需读取。
```
```md
Kafka作为一个集群运行在一个或多个可跨多个数据中心的服务器上。
Kafka集群以称为主题的类别存储记录流。
每条记录由一个键，一个值和一个时间戳组成。
```
## 分布式流平台
* 关键功能
```md
1. Publish and subscribe to streams of records, 
    similar to a message queue or enterprise messaging system.
2. Store streams of records in a fault-tolerant durable way.
3. Process streams of records as they occur.
```
## 应用
```md
Kafka通常用于两大类应用：
1. 构建可在系统或应用程序之间可靠获取数据的实时流数据管道，
2. 构建转换或响应数据流的实时流应用程序。
```
### [Use cases](https://kafka.apache.org/uses)
```md
1. Messaging
    Kafka可以替代更传统的消息代理。消息代理的使用有多种原因（将处理与数据生成器分离，缓冲未处理的消息等）。
    与大多数消息传递系统相比，Kafka具有更好的吞吐量，内置分区，复制和容错功能，这使其成为大规模消息处理应用程序的理想解决方案。
    根据我们的经验，消息传递的使用通常相对较低，但可能需要较低的端到端延迟，并且通常取决于Kafka提供的强大的耐用性保证。
    在这个领域，Kafka可与传统的消息传递系统（如ActiveMQ 或RabbitMQ）相媲美。
2. Website Activity Tracking
    Kafka的原始用例是能够将用户活动跟踪管道重建为一组实时发布 - 订阅源。
    这意味着站点活动（页面查看，搜索或用户可能采取的其他操作）将发布到中心主题，每个活动类型包含一个主题。
    这些供稿可用于订购一系列用例，包括实时处理，实时监控以及加载到 Hadoop 或离线数据仓库系统以进行离线处理和报告。
    活动跟踪通常非常高，因为为每个用户页面视图生成了许多活动消息。
3. Metrics
    Kafka通常用于运营监控数据。
    这涉及从分布式应用程序聚合统计信息以生成操作数据的集中式提要。
4. Log Aggregation
    日志聚合通常从服务器收集物理日志文件，并将它们放在中央位置（可能是文件服务器或 HDFS ）进行处理。
    Kafka抽象出文件的细节，并将日志或事件数据更清晰地抽象为消息流。
    这允许更低延迟的处理并更容易支持多个数据源和分布式数据消耗。
    与 Scribe 或 Flume 等以日志为中心的系统相比，Kafka提供了同样出色的性能，由于复制而具有更强的耐用性保证，以及更低的端到端延迟。
5. Stream Processing
    原始输入数据从Kafka主题中消费，然后汇总，丰富或以其他方式转换为新主题以供进一步消费或后续处理。
    例如，用于推荐新闻文章的处理管道可以从RSS订阅源抓取文章内容并将其发布到“文章”主题;
    进一步处理可能会对此内容进行规范化或重复数据删除，并将已清理的文章内容发布到新主题;
    最终处理阶段可能会尝试向用户推荐此内容。
    从0.10.0.0开始，Apache Kafka 中提供了一个名为Kafka Streams的轻量级但功能强大的流处理库，用于执行上述数据处理。
6. Event Sourcing
    事件源是一种应用程序设计风格，其中状态更改被记录为按时间排序的记录序列。
    Kafka对非常大的存储日志数据的支持使其成为以这种风格构建的应用程序的出色后端。
7. Commit Log
    Kafka可以作为分布式系统的一种外部提交日志。
    该日志有助于在节点之间复制数据，并充当故障节点恢复其数据的重新同步机制。
    Kafka中的日志压缩功能有助于支持此用法。
    在这种用法中，Kafka 类似于 Apache BookKeeper 项目。
```

### 承担数据交换枢纽的角色
```md
在公司的大数据生态系统中，可以把Kafka作为数据交换枢纽，
不同类型的分布式系统（关系数据库、NoSQL数据库、流处理系统、批处理系统等），可以统一接入到Kafka，
实现和 Hadoop 各个组件之间的不同类型数据的实时高效交换，较好地满足各种企业应用需求。
```
![](z_pic/Kafka-data-hub.jpeg)
```md
同时，借助于Kafka作为交换枢纽，也可以很好地解决不同系统之间的数据生产/消费速率不同的问题。
```

