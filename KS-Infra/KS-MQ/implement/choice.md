# 消息中间件选型

## 要点
### 功能维度
* 优先级队列
```md
优先级高的消息具备优先被消费的特权，这样可以为下游提供不同消息级别的保证。
优先级也是需要有一个前提的：如果消费者的消费速度大于生产者的速度，
并且消息中间件服务器（一般简单的称之为Broker）中没有消息堆积，那么对于发送的消息设置优先级也就没有什么实质性的意义了
```
* 延迟队列
```md
当你在网上购物的时候是否会遇到这样的提示：“三十分钟之内未付款，订单自动取消”？这个是延迟队列的一种典型应用场景。
延迟队列存储的是对应的延迟消息，所谓“延迟消息”是指当消息被发送以后，并不想让消费者立刻拿到消息，
而是等待特定时间后，消费者才能拿到这个消息进行消费。

1. 基于消息的延迟
   是指为每条消息设置不同的延迟时间，那么每当队列中有新消息进入的时候就会重新根据延迟时间排序，当然这也会对性能造成极大的影响。
2. 基于队列的延迟
    实际应用中大多采用基于队列的延迟，设置不同延迟级别的队列，比如5s、10s、30s、1min、5mins、10mins等，
    每个队列中消息的延迟时间都是相同的，这样免去了延迟排序所要承受的性能之苦，通过一定的扫描策略（比如定时）即可投递超时的消息。
```
* 死信队列
```md
由于某些原因消息无法被正确的投递，为了确保消息不会被无故的丢弃，一般将其置于一个特殊角色的队列，这个队列一般称之为死信队列。
与此对应的还有一个“回退队列”的概念，试想如果消费者在消费时发生了异常，那么就不会对这一次消费进行确认（Ack）,
进而发生回滚消息的操作之后消息始终会放在队列的顶部，然后不断被处理和回滚，导致队列陷入死循环。
为了解决这个问题，可以为每个队列设置一个回退队列，它和死信队列都是为异常的处理提供的一种机制保障。
实际情况下，回退队列的角色可以由死信队列和重试队列来扮演。
```
* 重试队列
```md
重试队列其实可以看成是一种回退队列，具体指消费端消费消息失败时，为防止消息无故丢失而重新将消息回滚到Broker中。
与回退队列不同的是重试队列一般分成多个重试等级，每个重试等级一般也会设置重新投递延时，重试次数越多投递延时就越大。

举个例子：消息第一次消费失败入重试队列Q1，Q1的重新投递延迟为5s，在5s过后重新投递该消息；
如果消息再次消费失败则入重试队列Q2，Q2的重新投递延迟为10s，在10s过后再次投递该消息。
以此类推，重试越多次重新投递的时间就越久，为此需要设置一个上限，超过投递次数就入死信队列。
重试队列与延迟队列有相同的地方，都是需要设置延迟级别，
它们彼此的区别是：延迟队列动作由内部触发，重试队列动作由外部消费端触发；延迟队列作用一次，而重试队列的作用范围会向后传递。
```
* 消费模式
```md
消费模式分为推（push）模式和拉（pull）模式。

推模式是指由Broker主动推送消息至消费端，实时性较好，不过需要一定的流制机制来确保服务端推送过来的消息不会压垮消费端。
拉模式是指消费端主动向Broker端请求拉取（一般是定时或者定量）消息，实时性较推模式差，但是可以根据自身的处理能力而控制拉取的消息量。
```
* 广播消费
```md
消息一般有两种传递模式：点对点（P2P，Point-to-Point）模式和发布/订阅（Pub/Sub）模式。

对于点对点的模式而言，消息被消费以后，队列中不会再存储，所以消息消费者不可能消费到已经被消费的消息。
虽然队列可以支持多个消费者，但是一条消息只会被一个消费者消费。

发布订阅模式定义了如何向一个内容节点发布和订阅消息，这个内容节点称为主题（topic），
主题可以认为是消息传递的中介，消息发布者将消息发布到某个主题，而消息订阅者则从主题中订阅消息。
主题使得消息的订阅者与消息的发布者互相保持独立，不需要进行接触即可保证消息的传递，发布/订阅模式在消息的一对多广播时采用。

RabbitMQ是一种典型的点对点模式，而Kafka是一种典型的发布订阅模式。
但是RabbitMQ中可以通过设置交换器类型来实现发布订阅模式而达到广播消费的效果，
Kafka中也能以点对点的形式消费，你完全可以把其消费组（consumer group）的概念看成是队列的概念。
不过对比来说，Kafka中因为有了消息回溯功能的存在，对于广播消费的力度支持比RabbitMQ的要强。
```
* 消息回溯
```md
一般消息在消费完成之后就被处理了，之后再也不能消费到该条消息。
消息回溯正好相反，是指消息在消费完成之后，还能消费到之前被消费掉的消息。

对于消息而言，经常面临的问题是“消息丢失”，至于是真正由于消息中间件的缺陷丢失还是由于使用方的误用而丢失一般很难追查，
如果消息中间件本身具备消息回溯功能的话，可以通过回溯消费复现“丢失的”消息进而查出问题的源头之所在。
消息回溯的作用远不止与此，比如还有索引恢复、本地缓存重建，有些业务补偿方案也可以采用回溯的方式来实现。
```
* 消息堆积+持久化
```md
流量削峰是消息中间件的一个非常重要的功能，而这个功能其实得益于其消息堆积能力。
从某种意义上来讲，如果一个消息中间件不具备消息堆积的能力，那么就不能把它看做是一个合格的消息中间件。

消息堆积分内存式堆积和磁盘式堆积。
RabbitMQ是典型的内存式堆积，但这并非绝对，在某些条件触发后会有换页动作来将内存中的消息换页到磁盘（换页动作会影响吞吐），
或者直接使用惰性队列来将消息直接持久化至磁盘中。
Kafka是一种典型的磁盘式堆积，所有的消息都存储在磁盘中。
一般来说，磁盘的容量会比内存的容量要大得多，对于磁盘式的堆积其堆积能力就是整个磁盘的大小。
从另外一个角度讲，消息堆积也为消息中间件提供了冗余存储的功能。援引纽约时报的案例，其直接将Kafka用作存储系统。
```
* 消息追踪
```md
对于分布式架构系统中的链路追踪（trace）而言，大家一定不会陌生。
对于消息中间件而言，消息的链路追踪（以下简称消息追踪）同样重要。对于消息追踪最通俗的理解就是要知道消息从哪来，存在哪里以及发往哪里去。
基于此功能下，我们可以对发送或者消费完的消息进行链路追踪服务，进而可以进行问题的快速定位与排查。
```
* 消息过滤
```md
消息过滤是指按照既定的过滤规则为下游用户提供指定类别的消息。
就以kafka而言，完全可以将不同类别的消息发送至不同的topic中，由此可以实现某种意义的消息过滤，
或者 Kafka 还可以根据分区对同一个topic中的消息进行分类。
不过更加严格意义上的消息过滤应该是对既定的消息采取一定的方式按照一定的过滤规则进行过滤。
同样以Kafka为例，可以通过客户端提供的 ConsumerInterceptor 接口或者Kafka Stream 的 filter 功能进行消息过滤。
```
* 多租户
```md
也可以称为多重租赁技术，是一种软件架构技术，主要用来实现多用户的环境下公用相同的系统或程序组件，并且仍可以确保各用户间数据的隔离性。

RabbitMQ就能够支持多租户技术，每一个租户表示为一个vhost，
其本质上是一个独立的小型RabbitMQ服务器，又有自己独立的队列、交换器及绑定关系等，并且它拥有自己独立的权限。
vhost就像是物理机中的虚拟机一样，它们在各个实例间提供逻辑上的分离，为不同程序安全保密地允许数据，
它既能将同一个RabbitMQ中的众多客户区分开，又可以避免队列和交换器等命名冲突。
```
* 多协议支持
```md
消息是信息的载体，为了让生产者和消费者都能理解所承载的信息（生产者需要知道如何构造消息，消费者需要知道如何解析消息），
它们就需要按照一种统一的格式描述消息，这种统一的格式称之为消息协议。
有效的消息一定具有某种格式，而没有格式的消息是没有意义的。

一般消息层面的协议有AMQP、MQTT、STOMP、XMPP 等（消息领域中的JMS更多的是一个规范而不是一个协议），
支持的协议越多其应用范围就会越广，通用性越强，
比如RabbitMQ 能够支持MQTT协议就让其在物联网应用中获得一席之地。
还有的消息中间件是基于其本身的私有协议运转的，典型的如Kafka。
```
* 跨语言支持
```md
消息中间件本身具备应用解耦的特性，如果能够进一步的支持多客户端语言，那么就可以将此特性的效能扩大。
跨语言的支持力度也可以从侧面反映出一个消息中间件的流行程度。
```
* 流量控制
```md
流量控制（flow control）针对的是发送方和接收方速度不匹配的问题，
提供一种速度匹配服务抑制发送速率使接收方应用程序的读取速率与之相适应。
通常的流控方法有Stop-and-wait、滑动窗口以及令牌桶等。
```
* 消息顺序性
```md
顾名思义，消息顺序性是指保证消息有序。
这个功能有个很常见的应用场景就是CDC（Change Data Chapture），
以MySQL为例，如果其传输的binlog的顺序出错，比如原本是先对一条数据加1，
然后再乘以2，发送错序之后就变成了先乘以2后加1了，造成了数据不一致。
```
* 安全机制
```md
在Kafka 0.9版本之后就开始增加了身份认证和权限控制两种安全机制。
身份认证是指客户端与服务端连接进行身份认证，
包括客户端与Broker之间、Broker与Broker之间、Broker与ZooKeeper之间的连接认证，目前支持SSL、SASL等认证机制。
权限控制是指对客户端的读写操作进行权限控制，包括对消息或Kafka集群操作权限控制。
权限控制是可插拔的，并支持与外部的授权服务进行集成。

对于RabbitMQ而言，其同样提供身份认证（TLS/SSL、SASL）和权限控制（读写操作）的安全机制。
```
* 消息幂等性
```md
对于确保消息在生产者和消费者之间进行传输而言一般有三种传输保障（delivery guarantee）
1. At most once 至多一次，消息可能丢失，但绝不会重复传输
2. At least once，至少一次，消息绝不会丢，但是可能会重复
3. Exactly once，精确一次，每条消息肯定会被传输一次且仅一次

对于大多数消息中间件而言，一般只提供At most once 和At least once 两种传输保障，
对于第三种一般很难做到，由此消息幂等性也很难保证。

Kafka自0.11版本开始引入了幂等性和事务，Kafka的幂等性是指单个生产者对于单分区单会话的幂等，
而事务可以保证原子性地写入到多个分区，即写入到多个分区的消息要么全部成功，要么全部回滚，
这两个功能加起来可以让 Kafka 具备EOS（Exactly Once Semantic）的能力。

不过如果要考虑全局的幂等，还需要与从上下游方面综合考虑，即关联业务层面，幂等处理本身也是业务层面所需要考虑的重要议题。
以下游消费者层面为例，有可能消费者消费完一条消息之后没有来得及确认消息就发生异常，
等到恢复之后又得重新消费原来消费过的那条消息，那么这种类型的消息幂等是无法有消息中间件层面来保证的。
如果要保证全局的幂等，需要引入更多的外部资源来保证，比如以订单号作为唯一性标识，并且在下游设置一个去重表。
```
* 事务性消息
```md
事务本身是一个并不陌生的词汇，事务是由事务开始（Begin Transaction）和事务结束（End Transaction）之间执行的全体操作组成。
支持事务的消息中间件并不在少数，Kafka 和RabbitMQ 都支持，不过此两者的事务是指生产者发生消息的事务，要么发送成功，要么发送失败。
消息中间件可以作为用来实现分布式事务的一种手段，但其本身并不提供全局分布式事务的功能。
```
## 性能
* 吞吐量
```md
消息中间件的性能一般是指其吞吐量
虽然从功能维度上来说，RabbitMQ 的优势要大于 Kafka，
但是Kafka 的吞吐量要比RabbitMQ高出1至2个数量级，一般 RabbitMQ 的单机QPS在万级别之内，
而 Kafka 的单机 QPS可以维持在十万级别，甚至可以达到百万级。

消息中间件的吞吐量始终会受到硬件层面的限制。
以网卡带宽为例，如果单机单网卡的带宽为 1 Gbps，如果要达到百万级的吞吐，那么消息体大小不得超过(1Gb/8)/100W，即约等于134B，
换句话说如果消息体大小超过134B，那么就不可能达到百万级别的吞吐。这种计算方式同样可以适用于内存和磁盘。
```
* 时延
```md
时延作为性能维度的一个重要指标，却往往在消息中间件领域所被忽视，
因为一般使用消息中间件的场景对时效性的要求并不是很高，如果要求时效性完全可以采用RPC的方式实现。
```
```md
消息中间件具备消息堆积的能力，消息堆积越大也就意味着端到端的时延也就越长，
与此同时延时队列也是某些消息中间件的一大特色。
```
```md
消息中间件能够解耦系统，对于一个时延较低的消息中间件而言，
它可以让上游生产者发送消息之后可以迅速的返回，也可以让消费者更加快速的获取到消息，
在没有堆积的情况下可以让整体上下游的应用之间的级联动作更加高效，
虽然不建议在时效性很高的场景下使用消息中间件，但是如果所使用的消息中间件的时延方面比较优秀，那么对于整体系统的性能将会是一个不小的提升。
```
* 功能影响
```md
性能和功能很多时候是相悖的，鱼和熊掌不可兼得：
Kafka在开启幂等、事务功能的时候会使其性能降低
RabbitMQ 在开启 rabbitmq_tracing 插件的时候也会极大的影响其性能
```
## 可靠性+可用性
```md
消息中间件的可靠性是指对消息不丢失的保障程度；而消息中间件的可用性是指无故障运行的时间百分比，通常用几个9来衡量。
消息可靠性也是衡量消息中间件好坏的一个关键因素。尤其是在金融支付领域，消息可靠性尤为重要。

从狭义的角度来说，分布式系统架构是一致性协议理论的应用实现，对于消息可靠性和可用性而言也可以追溯到消息中间件背后的一致性协议。
对于Kafka而言，其采用的是类似PacificA的一致性协议，通过ISR（In-Sync-Replica）来保证多副本之间的同步，并且支持强一致性语义（通过 acks 实现）。
对应的RabbitMQ是通过镜像环形队列实现多副本及强一致性语义的。
多副本可以保证在 master 节点宕机异常之后可以提升 slave 作为新的 master 而继续提供服务来保障可用性。
```
```md
Kafka设计之初是为日志处理而生，给人们留下了数据可靠性要求不要的不良印象，但是随着版本的升级优化，其可靠性得到极大的增强。
就目前而言，在金融支付领域使用 RabbitMQ 居多，而在日志处理、大数据等方面Kafka使用居多，
随着 RabbitMQ性 能的不断提升和 Kafka 可靠性的进一步增强，相信彼此都能在以前不擅长的领域分得一杯羹。
```
* 同步刷盘
```md
同步刷盘是增强一个组件可靠性的有效方式，消息中间件也不例外，Kafka 和RabbitMQ 都可以支持同步刷盘，
但是笔者对同步刷盘有一定的疑问：绝大多数情景下，一个组件的可靠性不应该由同步刷盘这种极其损耗性能的操作来保障，而是采用多副本的机制来保证。
```
## 可扩展
```md
消息中间件的扩展能力能够增强其用可用能力及范围，比如前面提到的RabbitMQ支持多种消息协议，这个就是基于其插件化的扩展实现。
还有从集群部署上来讲，归功于Kafka的水平扩展能力，其基本上可以达到线性容量提升的水平，
在 LinkedIn 实践介绍中就提及了有部署超过千台设备的Kafka集群。
```
## 运维管理
```md
在消息中间件的使用过程中难免会出现各式各样的异常情况，
有客户端的，也有服务端的，那么怎样及时有效的进行监测及修复。
业务线流量有峰值又低谷，尤其是电商领域，那么怎样前进行有效的容量评估，尤其是大促期间？
脚踢电源、网线被挖等事件层出不穷，如何有效的做好异地多活？
这些都离不开消息中间件的衍生产品——运维管理。
```
* 申请、审核
* 监控、告警
```md
除了一般的监控项（比如硬件、GC等）之外，对于消息中间件还需要关注端到端时延、消息审计、消息堆积等方面。
对于RabbitMQ而言，最正统的监控管理工具莫过于rabbitmq_management插件了，
但是社区内还有AppDynamics, Collectd, DataDog, Ganglia, Munin, Nagios, New Relic, Prometheus, Zenoss等多种优秀的产品。
Kafka在此方面也毫不逊色，比如：Kafka Manager, Kafka Monitor, Kafka Offset Monitor, Burrow, 
Chaperone, Confluent Control Center等产品，尤其是 Cruise 还可以提供自动化运维的功能。
```
* 管理
* 容灾
* 部署
```md
不管是扩容、降级、版本升级、集群节点部署、还是故障处理都离不开管理工具的应用，一个配套完备的管理工具集可以在遇到变更时做到事半功倍。
故障可大可小，一般是一些应用异常，也可以是机器掉电、网络异常、磁盘损坏等单机故障，这些故障单机房内的多副本足以应付。
如果是机房故障就要涉及异地容灾了，关键点在于如何有效的进行数据复制，
对于Kafka而言，可以参考 MirrorMaker、uReplicator 等产品，而RabbitMQ 可以参考 Federation 和 Shovel。
```
## 社区力度及生态发展
```md
对于目前流行的编程语言而言，如Java、Python，如果你在使用过程中遇到了一些异常，基本上可以通过搜索引擎的帮助来得到解决，
因为一个产品用的人越多，踩过的坑也就越多，对应的解决方案也就越多。

对于消息中间件也同样适用，如果你选择了一种“生僻”的消息中间件，可能在某些方面运用的得心应手，
但是版本更新缓慢、遇到棘手问题也难以得到社区的支持而越陷越深；
相反如果你选择了一种“流行”的消息中间件，其更新力度大，不仅可以迅速的弥补之前的不足，
而且也能顺应技术的快速发展来变更一些新的功能，这样可以让你以“站在巨人的肩膀上”。
在运维管理维度我们提及了 Kafka 和 RabbitMQ 都有一系列开源的监控管理产品，这些正是得益于其社区及生态的迅猛发展。
```
## 选型误区
```md
是否真的需要一个消息中间件？
是否需要自己维护一套消息中间件？
是否真的有自研的必要？
目前市面上的消息中间件是否都真的无法满足目前业务需求？
团队是否有足够的能力、人力、财力、精力来支持自研？
```
```md
RabbitMQ 在于 routing，而 Kafka 在于streaming，了解其根本对于自己能够对症下药选择到合适的消息中间件尤为重要。
```
```md
消息中间件选型切忌一味的追求性能或者功能，性能可以优化，功能可以二次开发。
如果要在功能和性能方面做一个抉择的话，那么首选性能，因为总体上来说性能优化的空间没有功能扩展的空间大。
然而对于长期发展而言，生态又比性能以及功能都要重要。
```
```md
对于可靠性方面也容易存在一个误区:
想要找到一个产品来保证消息的绝对可靠，很不幸的是这世界上没有绝对的东西，只能说尽量趋于完美。
想要尽可能的保障消息的可靠性也并非单单只靠消息中间件本身，还要依赖于上下游，需要从生产端、服务端和消费端这3个维度去努力保证。
```
```md
消息中间件选型还有一个考量标准就是尽量贴合团队自身的技术栈体系，虽然说没有蹩脚的消息中间件只有蹩脚的程序员，
但是让一个C栈的团队去深挖 PhxQueue总比去深挖 Scala 编写的 Kafka 要容易的多。
```
```md
消息中间件大道至简：一发一存一消费，没有最好的消息中间件，只有最合适的消息中间件。
```
## Reference
* [Kafka vs RabbitMQ](http://www.iocoder.cn/Kafka/vs-rabbitmq/)



